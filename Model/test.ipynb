{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "DATA_PATH = 'C:/Users/MJ/Desktop/MyValue/NLP/Model/data/' #데이터경로 설정\n",
    "print('파일 크기: ')\n",
    "for file in os.listdir(DATA_PATH):\n",
    "    if 'txt' in file:\n",
    "        print(file.ljust(30)+str(round(os.path.getsize(DATA_PATH+ file) / 100000,2))+'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#트레인 파일 불러오기\n",
    "train_data = pd.read_csv(DATA_PATH + 'DATASET.txt', header = 0, delimiter = '\\t', quoting=3, encoding='cp949')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('학습데이터 전체 개수: {}'.format(len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#리뷰 전체길이 확인\n",
    "train_length = train_data['발화'].astype(str).apply(len)\n",
    "train_length.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#리뷰 통계 정보\n",
    "print('리뷰 길이 최댓값: {}'.format(np.max(train_length)))\n",
    "print('리뷰 길이 최솟값: {}'.format(np.min(train_length)))\n",
    "print('리뷰 길이 평균값: {:.2f}'.format(np.mean(train_length)))\n",
    "print('리뷰 길이 표준편차: {:.2f}'.format(np.std(train_length)))\n",
    "print('리뷰 길이 중간값: {}'.format(np.median(train_length)))\n",
    "print('리뷰 길이 제1사분위: {}'.format(np.percentile(train_length,25)))\n",
    "print('리뷰 길이 제3사분위: {}'.format(np.percentile(train_length,75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열 아닌 데이터 모두 제거\n",
    "train_review = [review for review in train_data['발화'] if type(review) is str]\n",
    "train_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 폰트 설정(.ttf파일 다운로드 후 실행)\n",
    "wordcloud = WordCloud(DATA_PATH+'ROKAF Sans Medium.ttf').generate(' '.join(train_review))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#긍정 1, 부정 0\n",
    "print('불안 리뷰 갯수: {}'.format(train_data['감정'].value_counts()[0]))\n",
    "print('슬픔 리뷰 갯수: {}'.format(train_data['감정'].value_counts()[1]))\n",
    "print('분노 리뷰 갯수: {}'.format(train_data['감정'].value_counts()[2]))\n",
    "print('기쁨 리뷰 갯수: {}'.format(train_data['감정'].value_counts()[3]))\n",
    "print('중립 리뷰 갯수: {}'.format(train_data['감정'].value_counts()[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "DATA_PATH = 'C:/Users/MJ/Desktop/MyValue/NLP/Model/data/'\n",
    "train_data = pd.read_csv(DATA_PATH + 'DATASET.txt', header = 0, delimiter = '\\t', quoting=3, encoding='cp949')\n",
    "\n",
    "train_data['발화'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 함수 만들기\n",
    "def preprocessing(review, okt, remove_stopwords = False, stop_words =[]):\n",
    "  #함수인자설명\n",
    "  # review: 전처리할 텍스트\n",
    "  # okt: okt객체를 반복적으로 생성하지 않고 미리 생성 후 인자로 받음\n",
    "  # remove_stopword: 불용어를 제거할지 여부 선택. 기본값 False\n",
    "  # stop_words: 불용어 사전은 사용자가 직접 입력, 기본값 빈 리스트\n",
    "\n",
    "  # 1. 한글 및 공백 제외한 문자 모두 제거\n",
    "  review_text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]','',review)\n",
    "  \n",
    "  #2. okt 객체를 활용하여 형태소 단어로 나눔\n",
    "  word_review = okt.morphs(review_text,stem=True)\n",
    "\n",
    "  if remove_stopwords:\n",
    "    #3. 불용어 제거(선택)\n",
    "    word_review = [token for token in word_review if not token in stop_words]\n",
    "  return word_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 텍스트 전처리\n",
    "stop_words = ['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한']\n",
    "okt = Okt()\n",
    "clean_train_review = []\n",
    "\n",
    "for review in train_data['발화']:\n",
    "  # 리뷰가 문자열인 경우만 전처리 진행\n",
    "  if type(review) == str:\n",
    "    clean_train_review.append(preprocessing(review, okt, remove_stopwords=True, stop_words= stop_words))\n",
    "  else:\n",
    "    clean_train_review.append([]) #str이 아닌 행은 빈칸으로 놔두기\n",
    "\n",
    "clean_train_review[:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
